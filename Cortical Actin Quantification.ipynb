{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46ce8fce",
   "metadata": {},
   "source": [
    "# Cortical Actin Quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3135e1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3370ffdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import product\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d89b698",
   "metadata": {},
   "source": [
    "## Extract Boundaries from Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d15b49",
   "metadata": {},
   "source": [
    "Videos avi files. Drift correction performed already using StackReg package on ImageJ. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d64f502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: filename for a video\n",
    "# Output: Arrays of binarized images for (1) cortical actin and (2) entire cell\n",
    "\n",
    "def extractData(fileName):\n",
    "    \n",
    "    # Array of binarized image of cortical actin for each frame\n",
    "    CortActinSeries = []\n",
    "    \n",
    "    # Array of binarized image of whole cell for each frame\n",
    "    AllCellSeries = []\n",
    "    \n",
    "    # Array of contours for cortical actin for each frame\n",
    "    ContoursSeries = []\n",
    "\n",
    "    # Extract video information\n",
    "    cap = cv2.VideoCapture(fileName)\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # Make object to save the video\n",
    "#     saveName = fileName[:-4] + 'Modified.avi'  # change the file name if needed\n",
    "#     imgSize = (height * 2, width)\n",
    "#     frame_per_second = fps\n",
    "#     writer = cv2.VideoWriter(saveName, cv2.VideoWriter_fourcc(*'DIVX'), frame_per_second, imgSize)\n",
    "\n",
    "    # Loop through all frames\n",
    "    while(cap.isOpened()):\n",
    "        ret, frame = cap.read()\n",
    "        if ret==True:\n",
    "\n",
    "            # Convert color to gray, remove timer/scale bar, erode, binarize, save\n",
    "            grayImg = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            for i,j in product(range(50), range(100)):\n",
    "                grayImg[i, j] = 0\n",
    "            for i,j in product(range(height - 50, height), range(width - 200, width)):\n",
    "                grayImg[i, j] = 0\n",
    "            kernel = np.ones((3, 3), np.uint8)\n",
    "            blurImg = cv2.GaussianBlur(grayImg,(3,3),0)\n",
    "            erodeImg = cv2.erode(blurImg, kernel, iterations=1)\n",
    "            \n",
    "            # Cortical Actin - 30 set as threshold for all images\n",
    "            ret, binImg = cv2.threshold(erodeImg,30,255,cv2.THRESH_BINARY)\n",
    "            CortActinSeries.append(binImg)\n",
    "            \n",
    "            # Entire Cell\n",
    "            ret, binImgAll = cv2.threshold(erodeImg,0,255,cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            AllCellSeries.append(binImgAll)\n",
    "\n",
    "            # Contours for Cortical Actin\n",
    "            contours, hierarchy = cv2.findContours(binImg, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "            ContoursSeries.append(contours)\n",
    "            \n",
    "            # Display original and binarized images with contours\n",
    "            binImgColor = cv2.cvtColor(binImg,cv2.COLOR_GRAY2RGB)\n",
    "            cv2.drawContours(binImgColor, contours, -1, (0,255,0), 0)\n",
    "            combined = np.concatenate((frame, binImgColor), axis = 1)\n",
    "#             writer.write(combined)\n",
    "            cv2.imshow('frame',combined)\n",
    "            if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "#     writer.release()\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "    return CortActinSeries, AllCellSeries, length, width, height"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c128db3",
   "metadata": {},
   "source": [
    "## Quantify Difference Across Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8173f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: Arrays of binarized images for (1) cortical actin and (2) entire cell + length/width/height of images\n",
    "# Ouput: Representative metrics: avDiff is average number of pixels changing between frames, avActin is average \n",
    "# of pixels classified as actin, and avCell is average number of pixels classified as cell\n",
    "\n",
    "def quantifyChange(CortActinSeries, AllCellSeries, length, width, height):\n",
    "    avDiff = []\n",
    "    avActin = []\n",
    "    avCell = []\n",
    "    for k in range(length - 1):\n",
    "        diffs = 0 \n",
    "        totalCortActin = 0\n",
    "        totalCell = 0\n",
    "        # Cosnider images in pairs\n",
    "        for i,j in product(range(height), range(width)):\n",
    "            currentVal = CortActinSeries[k][i, j]\n",
    "            nextVal = CortActinSeries[k + 1][i, j]\n",
    "            if currentVal != nextVal:\n",
    "                diffs += 1\n",
    "            if currentVal == 255:\n",
    "                totalCortActin += 1\n",
    "            if AllCellSeries[k][i, j] == 255:\n",
    "                totalCell += 1\n",
    "        avDiff.append(diffs)\n",
    "        avActin.append(totalCortActin)\n",
    "        avCell.append(totalCell)\n",
    "    return np.mean(avDiff), np.mean(avActin), np.mean(avCell)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f27f6f",
   "metadata": {},
   "source": [
    "## Visualize Actin Across all Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1455a6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs: Array of binarized images for cortical actin and image name\n",
    "# Output: Saves figure with cumulative actin at each location over time series at designated location\n",
    "\n",
    "def makePlots(CortActinSeries, image):\n",
    "    total = np.zeros(CortActinSeries[0].shape)\n",
    "    for n in CortActinSeries:\n",
    "        total += n\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.contourf(total, 100, cmap=plt.cm.nipy_spectral)\n",
    "    plt.title(image[:-4])\n",
    "    plt.axis('off')\n",
    "#     plt.colorbar()\n",
    "    plt.savefig(\"Cortical Actin/Figures/Superimposed \" + image[:-4] + \".png\", dpi = 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b45bd1",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7829d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainFunction(path, images):\n",
    "    avDiffAll = []\n",
    "    avActinAll = []\n",
    "    avCellAll = []\n",
    "    for image in images:\n",
    "        if '.avi' in image and 'Modified' not in image:\n",
    "            print(image)\n",
    "            CortActinSeries, AllCellSeries, length, width, height = extractData(path + '/' + image)\n",
    "            avDiff, avActin, avCell = quantifyChange(CortActinSeries, AllCellSeries, length, width, height)\n",
    "            makePlots(CortActinSeries, image)\n",
    "            avDiffAll.append(avDiff)\n",
    "            avActinAll.append(avActin)\n",
    "            avCellAll.append(avCell)\n",
    "    return avDiffAll, avActinAll, avCellAll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94aa999",
   "metadata": {},
   "source": [
    "## Dancing Project Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e355113",
   "metadata": {},
   "source": [
    "### Day 0 Lifeact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98029d54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SG\n",
    "path = \"\"\n",
    "images = os.listdir(path)\n",
    "images.sort()\n",
    "avDiffAll_SG0, avActinAll_SG0, avCellAll_SG0 = mainFunction(path, images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaff9489",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CG\n",
    "path = \"\"\n",
    "images = os.listdir(path)\n",
    "images.sort()\n",
    "avDiffAll_CG0, avActinAll_CG0, avCellAll_CG0 = mainFunction(path, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967f7736",
   "metadata": {},
   "source": [
    "### Day 4 Lifeact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef211933",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# SG\n",
    "path = \"\"\n",
    "images = os.listdir(path)\n",
    "images.sort()\n",
    "avDiffAll_SG4, avActinAll_SG4, avCellAll_SG4 = mainFunction(path, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b04aab8",
   "metadata": {},
   "source": [
    "### Dataframe for All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df306be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SG D0 \n",
    "data = {'SG0 Differences': avDiffAll_SG0, 'Total Actin': avActinAll_SG0, 'Total Cell': avCellAll_SG0}\n",
    "df_SG_D0 = pd.DataFrame(data)\n",
    "# CG D0\n",
    "data = {'CG0 Differences': avDiffAll_CG0, 'Total Actin': avActinAll_CG0, 'Total Cell': avCellAll_CG0}\n",
    "df_CG_D0 = pd.DataFrame(data)\n",
    "# SG D4\n",
    "data = {'SG4 Differences': avDiffAll_SG4, 'Total Actin': avActinAll_SG4, 'Total Cell': avCellAll_SG4}\n",
    "df_SG_D4 = pd.DataFrame(data)\n",
    "# Combine All data\n",
    "allData = pd.concat([df_SG_D0, df_CG_D0, df_SG_D4], axis=1)\n",
    "allData.to_csv(\"Cortical Actin/Final Data/allData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83db53e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ab1dab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
